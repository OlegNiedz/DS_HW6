{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Завдання"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Дане домашнє завдання буде повністю пов'язане з лінійною регресією та її реалізацією. Отож розіб'ємо наше домашнє завдання на декілька частин:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - напишіть функцію гіпотези лінійної регресії у векторному вигляді;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "\n",
    "def hypothesis(X, w):\n",
    "    \"\"\"\n",
    "    Гіпотеза лінійної регресії у векторному вигляді.\n",
    "\n",
    "    Параметри:\n",
    "    X : numpy array\n",
    "        Матриця ознак (рядки - приклади, стовпці - ознаки).\n",
    "    w : numpy array\n",
    "        Вектор параметрів моделі.\n",
    "\n",
    "    Повертає:\n",
    "    numpy array\n",
    "        Прогнозовані значення.\n",
    "    \"\"\"\n",
    "    return np.dot(X, w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - створіть функцію для обчислення функції втрат у векторному вигляді;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_function(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Функція втрат у векторному вигляді (середньоквадратична похибка).\n",
    "\n",
    "    Параметри:\n",
    "    y_true : numpy array\n",
    "        Реальні значення.\n",
    "    y_pred : numpy array\n",
    "        Прогнозовані значення.\n",
    "\n",
    "    Повертає:\n",
    "    float\n",
    "        Значення функції втрат.\n",
    "    \"\"\"\n",
    "    return np.mean((y_true - y_pred) ** 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - реалізуйте один крок градієнтного спуску;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent_step(X, y, w, learning_rate):\n",
    "    \"\"\"\n",
    "    Один крок градієнтного спуску.\n",
    "\n",
    "    Параметри:\n",
    "    X : numpy array\n",
    "        Матриця ознак (рядки - приклади, стовпці - ознаки).\n",
    "    y : numpy array\n",
    "        Вектор реальних значень.\n",
    "    w : numpy array\n",
    "        Вектор параметрів моделі.\n",
    "    learning_rate : float\n",
    "        Швидкість навчання.\n",
    "\n",
    "    Повертає:\n",
    "    numpy array\n",
    "        Оновлені параметри моделі.\n",
    "    \"\"\"\n",
    "    predictions = hypothesis(X, w)\n",
    "    gradient = np.dot(X.T, predictions - y) / len(y)\n",
    "    w -= learning_rate * gradient\n",
    "    return w"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - знайдіть найкращі параметри w для датасету використовуючи написані вами функції, прогнозуючу ціну на будинок залежно від площі, кількості ванних кімнат та кількості спалень;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent(X, y, w, learning_rate, iterations):\n",
    "    for _ in range(iterations):\n",
    "        w = gradient_descent_step(X, y, w, learning_rate)\n",
    "    return w\n",
    "\n",
    "\n",
    "# Приклад використання:\n",
    "# X - матриця ознак\n",
    "# y - вектор цільових значень\n",
    "# w - початкові значення параметрів\n",
    "# learning_rate - швидкість навчання\n",
    "# iterations - кількість ітерацій\n",
    "\n",
    "# Отримання параметрів за допомогою градієнтного спуску\n",
    "# best_w = gradient_descent(X, y, w, learning_rate, iterations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - знайдіть ці ж параметри за допомогою аналітичного рішення;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analytical_solution(X, y):\n",
    "    return np.linalg.inv(X.T @ X) @ X.T @ y\n",
    "\n",
    "\n",
    "# Приклад використання:\n",
    "# best_theta_analytical = analytical_solution(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - для перевірки спрогнозованих значень, використайте LinearRegression з бібліотеки scikit-learn та порівняйте результати."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
